---
layout: post
title:  "Autonomous Attendance using Face recognition - Winning the Newton Bhabha Foundation Technology Challenge"
author: aniruddh
categories: [ Machine Learning ]
image: https://aniruddh-chandratre-e877.netlify.app/static/4d13d8e5593357102ade42f78c3a4d6e/caed1/28234875_2280969695262286_6816469426306889221_o-1.jpg
toc: true
---

## Introduction
Attendance is one of the prime activities that take place in some universities (where strict attendance rules exist, such as NMIMS). The attendance process is mundane and time taking. However, what if you could have a simple app which can take a picture and mark attendance automatically!

We are now living in an era that has revolutionised our way of working, thinking and acting. Everything we do is simply a click away. We are children of the digital age.

Attendance is a mandatory routine of every class. Traditionally at least 5-10 minutes of class time is wasted while accomplishing this task. Thatâ€™s roughly 8-10% of lecture time. Apart from this, discrepancies in attendance can occur based on human error or due to undesirable means. This mundane activity can easily be avoided, thereby saving time and effort while increasing efficiency.

Can smartly be substituted by artificially intelligent algorithms which are invariant to environment conditions and require almost negligible cost. Such an autonomous system creates a more justified and unidirectional approach thereby limiting delayed or misrepresented entries.

## How does it work?

The pipeline can be broken down into 4 major stages.


1. Upload : The upload stage deals with uploading of images to the attendance server. For this, I created a simple web application, as well as an android application.
2. Recognise : The recognition stage can be further broken down into two sub-stages : (a) Detect, (b) Recognise. We well talk about this in a moment.
3. Sort : The recognition stage provides a list of students that are present in the image. For marking attendance, the list is then matched with the class database and then the present/absent members are classified.
4. Mark : This stage deals with using the data that has been computed above and marking the attendance on the university database.

### Face recognition
So how does the application recognise the faces in a given image? The overall pipeline is quite generic. We first pass the image through a detector, which provides us with the bounding boxes of each face. From the bounding box co-ordinates, we can then create a specific region of interest and then apply a classification algorithm. This is where we introduce a new method for classification of faces.

Initially during the competition, I made use of a SVM for classification of faces. (after getting a feature vector representation using DLib) But later on, I implemented an approximate nearest neighbour search using a random forest composed of binary trees. This kind of implementation provides extreme scalability with large amounts of data and people.

### Detection
For detection, I made use of DLib face detector to get the bounding box of the frame. After getting the region of interest, I applied a affine transformation for alignment. (Inspired by OpenFace).


### Approximate Nearest Neighbours Search
To understand the concept, lets consider a scatter plot of some 2D data and then start off by creating different trees! We will have random splits in the scatter plot until we have only K elements in each section.

![alt](https://lh3.googleusercontent.com/1OQJ69_GT66ki4FqzsZrqX78E1qsX9pRXkTsig95PIIv1D_DfKR4-4PzdbBeG3Zjlw_atWFd5-rA8zyHCccry8La95D08AQ_OoPO-Af6QQ-ETaiYgcS-1kxlszGxsm9s_VvXZrASsnU)
![alt](https://lh5.googleusercontent.com/rJCKK5eh_fTPuK4uB4G7hFgm_RJIz0zu3ZF4iBHlh7mmaAqFQlo40GG9FLWeCWYERAVQQLcHW323JJHpViEHWZ4efSCwYg1Nkr44Af9AkJRRvwwmiVDVC2bY1NC9i_uyYyKVHBZ9tas)

The corresponding tree would be 

![alt](https://lh3.googleusercontent.com/ThWZZKFcO5ykD-b3cbhfV_z1vZZ41hzHf7y3UP9zkI1Z6bbGWRtKf-MIPcbLJJGN9LAPGR5oDFhGOSNrPp5AO9ty3b2eG4-zhiT5sF1pS-clDXuoyp2-2OBG4rb7zCJngAUfw_yRXyo)

We keep doing this till we have only K elements in each section. The end result looks like this :

![alt](https://lh6.googleusercontent.com/cAXdppy2QH-IHOcFtYNvLYoKROBVEUW4g61-njiyspD6zeUoiHHHmHUs3O6orir0WYmnbGkcJDCHq2LgITpybiddDI2AN-SJNF8otTEZssm_goWuH3IUQ8cHuVpz_ityW_LRwb04Hu0)
![alt](https://lh4.googleusercontent.com/RyBq6mBtIATC5qD9q1VvL4L6GKWRNLE8kyJFAVLmLj9NmomlCmMJEYZon3hYqdAsacP82fH455i_WiH2Rel38eoRVUP_ipF7kT6NYw5LzEbhn_FmVAdI5Z5VXpWPEcL2P-hb1u6j_O4)

It is possible that during the creation of a single tree, we may have split the data that may cause unnecessary bias. To fix this, we create multiple trees. The group of multiple trees is a forest. We perform search of our query in all these trees together

![alt](https://lh3.googleusercontent.com/vxvE5eyGwaK1z_s1PsimYO_pkBRX0tpzFfjQ66xsrSVTnB32Q_A68yIY8cBrsMkr8lcAjdKxacuinUlsx5IrCQ16ZMZevBaVdbyqFioYsLbeZxurW3Mg73UwK8eckWgZifKUAM8zarM)

## Results
By doing this, I could achieve a maximum accuracy of 85% (by using SVM) on the test data that was provided. However, the application achieved 99.2% accuracy by using Approximate Nearest Neighbour search.  The test data consisted of 25 images for each person. The total number of people was 30. The solution out performed all the other teams at the competition and secured the first position at the Newton Bhabha Foundation Technology Challenge!

