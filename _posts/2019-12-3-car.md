---
layout: post
title:  "Edison (2018) - A miniature self driving car"
author: aniruddh
categories: [ Apps, Machine Learning, Robotics ]
image: https://aniruddh-chandratre-e877.netlify.app/static/eab085403950d768dfd959cc11abf0d6/a41d1/IMG_20180304_173155-2.jpg
toc: true
---

Edison is a miniature self driving electric car. I designed this car in the second year of my undergraduate studies as a mini-project. Upon completion of the project, I had the opportunity to demo the project at the Annual college technology festival, where I received the "best-demo" prize. 


## The car
The intent of this project was build a scaled down version of the traditional self driving system by using computer vision and deep learning and testing the car with real world scenarios. The project, at this scale, can be used as a research model for real world autonomous scenarios, without the dangers of the same. Along with that, it can be used as a remotely operated vehicle.

<iframe width="560" height="315" src="https://www.youtube.com/embed/8QErxVu38rs" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

## How does it work

The entire car runs on a single Raspberry Pi 3, along with a First Person View (FPV) camera.

For actuation of the rear motor, I have used an external PWM board, PCA9685 and a Brushed Motor Electronic Speed Controller (ESC).

For the front servo, I have connected it on the same PWM board.

On the controller side, I have a web server running on the raspberry pi, which can be controlled using an android app (as a http client).

Refer the schematic for a detailed connection guide!

![alt](https://lh5.googleusercontent.com/39gXREWj87ChRYj6R8AkH-nfvqbh2OfuvPS7UmCYxs77XtEvqbHbmJI45DHEP9spf-unLyA5wq-AKxC911bo9SVGkdpFXT84yb8aJvEWt5boXuOhZ7grmjtJAuHvL4ilyp8JpXN3)

## Autonomous? How?

Edison made use of a Convolutional Neural Network (CNN) which takes the input frame (120*160) in as the input and provides two outputs : `angle_out` and `throttle_out`. Refer to the diagram below for the network architecture!

![alt](https://lh3.googleusercontent.com/G4nR7bcyz4tNU7PnyHq8EWbFGmxa2ixnrNmR76RMt4hJv5vlCxRBx8DGHBe4uxNooVzLMZJj_JmnHn2xYGHKzjByabc4vFy9QbS9PbdgUk6dZg8UJWqUgQAU0_6-uS5gR9MVwQ3C)

The angle and the throttle has been scaled from `-1` to 1. In terms of angle, `-1` represents a full left, and `1` represents a full right. For the throttle, `-1` represents reverse at full speed and `1` represents forward at full speed.

## Show me charts

Here's a comparison chart for predicted v/s user inputs for a particular track!

![alt](https://lh6.googleusercontent.com/SGHwxrD-M2HCOdgvDw3bxypLsLGfK1Jizs1lIErMQVN7EuJgjWrzkSruVQ6L0G4mHNz8dq1NgMFDpLFNAid35sXP07zMlhEbQatF6c3aMtAYTbC5vBQ7iNOwZUiyPpuY96mTMNXU)